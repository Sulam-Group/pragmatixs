{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "from configs import get_config, Config\n",
    "from datasets import get_dataset\n",
    "\n",
    "config_name = \"imagenet\"\n",
    "# CUB\n",
    "# config_dict = {\n",
    "#     \"data.explanation_length\": [6, 12, 18, 24, 30],\n",
    "#     \"speaker.alpha\": [0.0, 0.2],\n",
    "#     \"listener.listener_type\": \"claim\",\n",
    "#     \"listener.gamma\": [0.0, 0.4, 0.8],\n",
    "# }\n",
    "# explanation_length = 6\n",
    "# vip_max_queries = 311\n",
    "# CheXpert\n",
    "# config_dict = {\n",
    "#     \"data.explanation_length\": [4, 6, 8],\n",
    "#     \"speaker.alpha\": [0.0, 0.2],\n",
    "#     \"listener.listener_type\": \"claim\",\n",
    "#     \"listener.gamma\": [0.0, 0.2, 0.4],\n",
    "# }\n",
    "# explanation_length = 4\n",
    "# ImageNet\n",
    "config_dict = {\n",
    "    \"data.explanation_length\": [12],\n",
    "    \"speaker.alpha\": [0.0, 0.2],\n",
    "    \"listener.listener_type\": \"claim\",\n",
    "    \"listener.gamma\": [0.4],\n",
    "}\n",
    "explanation_length = 12\n",
    "vip_max_queries = 399\n",
    "config = get_config(config_name, config_dict=config_dict)\n",
    "\n",
    "dataset = get_dataset(config, train=False, workdir=root_dir)\n",
    "classes = dataset.classes\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "\n",
    "results_dir = os.path.join(root_dir, \"results\", config.data.dataset.lower())\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_safe = config.data.classifier.lower().replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "results_path = os.path.join(results_dir, f\"{classifier_safe}.pkl\")\n",
    "\n",
    "results = pd.read_pickle(results_path)\n",
    "label = results[\"label\"]\n",
    "prediction = results[\"prediction\"]\n",
    "\n",
    "accuracy = (label == prediction).mean()\n",
    "print(f\"{classifier_safe} accuracy: {accuracy:.2%}\")\n",
    "\n",
    "confusion = confusion_matrix(label, prediction, normalize=\"true\")\n",
    "accuracy_per_class = np.diag(confusion)\n",
    "\n",
    "sorted_class_idx = np.argsort(accuracy_per_class)[::-1]\n",
    "sorted_classes = [classes[idx] for idx in sorted_class_idx]\n",
    "sorted_accuracy = accuracy_per_class[sorted_class_idx]\n",
    "\n",
    "print(\"Class-wise accuracy:\")\n",
    "for _, (class_name, acc) in enumerate(zip(sorted_classes, sorted_accuracy)):\n",
    "    print(f\"\\t{class_name}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dir = os.path.join(root_dir, \"figures\", \"accuracy\")\n",
    "os.makedirs(figure_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_accuracy(config: Config):\n",
    "    results = config.get_results()\n",
    "    results[\"listener_prediction\"] = results[\"action\"].apply(lambda x: np.argmax(x))\n",
    "    return (\n",
    "        results[\"explanation_accuracy\"].mean(),\n",
    "        (results[\"listener_prediction\"] == results[\"prediction\"]).mean(),\n",
    "    )\n",
    "\n",
    "\n",
    "lit_config, prag_config = config.sweep(keys=[\"speaker.alpha\"])\n",
    "\n",
    "lit_len_configs = lit_config.sweep(keys=[\"data.explanation_length\", \"listener.gamma\"])\n",
    "prag_len_configs = prag_config.sweep(keys=[\"data.explanation_length\", \"listener.gamma\"])\n",
    "\n",
    "results_data = {\n",
    "    \"speaker\": [],\n",
    "    \"gamma\": [],\n",
    "    \"explanation_length\": [],\n",
    "    \"explanation_accuracy\": [],\n",
    "    \"listener_accuracy\": [],\n",
    "}\n",
    "for _config in lit_len_configs + prag_len_configs:\n",
    "    if _config.speaker.alpha == 0.0:\n",
    "        speaker = \"literal\"\n",
    "    else:\n",
    "        speaker = \"pragmatic\"\n",
    "\n",
    "    explanation_accuracy, listener_accuracy = get_accuracy(_config)\n",
    "    results_data[\"speaker\"].append(speaker)\n",
    "    results_data[\"gamma\"].append(_config.listener.gamma)\n",
    "    results_data[\"explanation_length\"].append(_config.data.explanation_length)\n",
    "    results_data[\"explanation_accuracy\"].append(explanation_accuracy)\n",
    "    results_data[\"listener_accuracy\"].append(listener_accuracy)\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "lit_accuracy = results_df[\n",
    "    (results_df[\"speaker\"] == \"literal\")\n",
    "    & (results_df[\"explanation_length\"] == explanation_length)\n",
    "][\"listener_accuracy\"].values[0]\n",
    "prag_accuracy = results_df[\n",
    "    (results_df[\"speaker\"] == \"pragmatic\")\n",
    "    & (results_df[\"explanation_length\"] == explanation_length)\n",
    "][\"listener_accuracy\"].values[0]\n",
    "\n",
    "print(f\"Literal listener accuracy ({explanation_length} claims): {lit_accuracy:.2%}\")\n",
    "print(f\"Pragmatic listener accuracy ({explanation_length} claims): {prag_accuracy:.2%}\")\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(16 / 2, 9 / 4))\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    data=results_df,\n",
    "    x=\"explanation_length\",\n",
    "    y=\"explanation_accuracy\",\n",
    "    hue=\"speaker\",\n",
    "    style=\"gamma\",\n",
    "    marker=\"o\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Utterance length\")\n",
    "ax.set_ylabel(\"Explanation accuracy\")\n",
    "\n",
    "ax = axes[1]\n",
    "sns.lineplot(\n",
    "    data=results_df,\n",
    "    x=\"explanation_length\",\n",
    "    y=\"listener_accuracy\",\n",
    "    hue=\"speaker\",\n",
    "    style=\"gamma\",\n",
    "    marker=\"o\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Utterance length\")\n",
    "ax.set_ylabel(\"Listener accuracy\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.savefig(\n",
    "    os.path.join(figure_dir, f\"{config.data.dataset.lower()}.pdf\"), bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    os.path.join(figure_dir, f\"{config.data.dataset.lower()}.png\"), bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "vip_results_path = os.path.join(\n",
    "    results_dir, f\"{config.data.dataset.lower()}_vip_query{vip_max_queries}_sbiased.pkl\"\n",
    ")\n",
    "vip_results = pd.read_pickle(vip_results_path)\n",
    "\n",
    "prediction = np.array(vip_results[\"prediction\"].values.tolist())\n",
    "vip_logits = np.array(vip_results[\"logits\"].values.tolist())\n",
    "\n",
    "vip_prediction = np.argmax(vip_logits, axis=-1)\n",
    "vip_accuracy = np.mean(vip_prediction == prediction[:, None], axis=0)\n",
    "print(\"V-IP accuracy:\")\n",
    "for n_queries, accuracy in enumerate(vip_accuracy):\n",
    "    print(f\"\\t{n_queries + 1} queries: {accuracy:.2%}\")\n",
    "\n",
    "explanation_length = results_df[\"explanation_length\"].unique()\n",
    "explanation_length = np.sort(explanation_length)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(16 / 4, 9 / 4))\n",
    "ax.plot(\n",
    "    explanation_length,\n",
    "    vip_accuracy[explanation_length - 1],\n",
    "    label=\"V-IP\",\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=results_df,\n",
    "    x=\"explanation_length\",\n",
    "    y=\"listener_accuracy\",\n",
    "    hue=\"speaker\",\n",
    "    style=\"gamma\",\n",
    "    marker=\"o\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Utterance length\")\n",
    "ax.set_ylabel(\"Listener accuracy\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.savefig(\n",
    "    os.path.join(figure_dir, f\"{config.data.dataset.lower()}_vip.pdf\"),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.savefig(\n",
    "    os.path.join(figure_dir, f\"{config.data.dataset.lower()}_vip.png\"),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8fbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
