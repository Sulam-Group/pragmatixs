{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import reverse_cuthill_mckee\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "from datasets import CUB\n",
    "from classifiers import CLIPClassifier\n",
    "from speaker_model import ClaimSpeaker\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "backbone = \"ViT-L/14\"\n",
    "classifier = CLIPClassifier(backbone, device=device)\n",
    "\n",
    "dataset = CUB(data_dir, train=False)\n",
    "classes = dataset.classes\n",
    "claims = dataset.claims\n",
    "\n",
    "speaker = ClaimSpeaker(classifier, len(classes), claims, device=device)\n",
    "state_path = os.path.join(root_dir, \"weights\", f\"cub_10_0.0_0.4_8.pt\")\n",
    "state = torch.load(state_path, map_location=device)\n",
    "speaker.load_state_dict(state[\"speaker\"])\n",
    "\n",
    "pragmatic_speaker = ClaimSpeaker(classifier, len(classes), claims, device=device)\n",
    "state_path = os.path.join(root_dir, \"weights\", f\"cub_10_0.1_0.4_8.pt\")\n",
    "state = torch.load(state_path, map_location=device)\n",
    "pragmatic_speaker.load_state_dict(state[\"speaker\"])\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    class_prompts = [f\"This is a picture of a {c}\" for c in classes]\n",
    "    clip_class_embeddings = classifier.encode_text(class_prompts)\n",
    "    clip_class_corr = torch.matmul(clip_class_embeddings, clip_class_embeddings.T)\n",
    "    clip_class_corr = clip_class_corr.cpu().numpy()\n",
    "\n",
    "    speaker_class_embeddings = speaker.class_embedding.weight\n",
    "    speaker_class_embeddings /= torch.norm(\n",
    "        speaker_class_embeddings, dim=-1, keepdim=True\n",
    "    )\n",
    "    speaker_class_corr = torch.matmul(\n",
    "        speaker_class_embeddings, speaker_class_embeddings.T\n",
    "    )\n",
    "    speaker_class_corr = speaker_class_corr.cpu().numpy()\n",
    "\n",
    "    pragmatic_speaker_class_embeddings = pragmatic_speaker.class_embedding.weight\n",
    "    pragmatic_speaker_class_embeddings /= torch.norm(\n",
    "        pragmatic_speaker_class_embeddings, dim=-1, keepdim=True\n",
    "    )\n",
    "    pragmatic_speaker_class_corr = torch.matmul(\n",
    "        pragmatic_speaker_class_embeddings, pragmatic_speaker_class_embeddings.T\n",
    "    )\n",
    "    pragmatic_speaker_class_corr = pragmatic_speaker_class_corr.cpu().numpy()\n",
    "\n",
    "# clip_class_graph = csr_matrix(clip_class_corr - np.eye(len(classes)))\n",
    "# class_order = reverse_cuthill_mckee(clip_class_graph)\n",
    "\n",
    "# ordered_clip_class_corr = clip_class_corr[class_order][:, class_order]\n",
    "# ordered_speaker_class_corr = speaker_class_corr[class_order][:, class_order]\n",
    "# ordered_pragmatic_speaker_class_corr = pragmatic_speaker_class_corr[class_order][\n",
    "#     :, class_order\n",
    "# ]\n",
    "\n",
    "_, axes = plt.subplots(1, 3, figsize=(16 / 2, 9 / 4))\n",
    "ax = axes[0]\n",
    "sns.heatmap(clip_class_corr, ax=ax, cbar=False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"CLIP class similarities\")\n",
    "\n",
    "ax = axes[1]\n",
    "sns.heatmap(speaker_class_corr, ax=ax, cbar=False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Speaker class similarities\")\n",
    "\n",
    "ax = axes[2]\n",
    "sns.heatmap(pragmatic_speaker_class_corr, ax=ax, cbar=False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Pragmatic speaker class similarities\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
