{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as t\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "from datasets import HAM\n",
    "from classifiers import BiomedCLIP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    \"hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\n",
    ")\n",
    "tokenizer = get_tokenizer(\n",
    "    \"hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\n",
    ")\n",
    "\n",
    "transform = t.Compose(\n",
    "    [\n",
    "        t.Resize((224, 224), antialias=True),\n",
    "        t.ToTensor(),\n",
    "        t.Normalize(\n",
    "            mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "            std=[0.26862954, 0.26130258, 0.27577711],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "dataset = HAM(root=data_dir, transform=transform)\n",
    "prompts = [f\"This is a photo of {class_name}\" for class_name in dataset.classes]\n",
    "print(\"\\n\".join(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "text = tokenizer(prompts).to(device)\n",
    "print(text.size())\n",
    "\n",
    "idx = np.random.choice(len(dataset), size=10)\n",
    "for _idx in idx:\n",
    "    image, label = dataset[_idx]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features, text_features, logit_scale = model(image, text)\n",
    "    logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
    "    print(label, torch.argsort(logits, dim=-1, descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
